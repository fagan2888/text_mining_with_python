{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 0: 02/20/2019 \tType: <class 'str'>\n",
      "DateT 0: 02/20/2019 \tType: <class 'datetime.datetime'>\n",
      "\n",
      "Match 1: 3/13/2019 \tType: <class 'str'>\n",
      "DateT 1: 03/13/2019 \tType: <class 'datetime.datetime'>\n",
      "\n",
      "Match 2: 10/1/3019 \tType: <class 'str'>\n",
      "DateT 2: 10/01/3019 \tType: <class 'datetime.datetime'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "date_str_1 = \"Today's date is 02/20/2019\"\n",
    "date_str_2 = \"Today the date is 3/13/2019\"\n",
    "date_str_3 = \"Today is 10/1/3019 and it's cold outside\"\n",
    "lst_pre = [date_str_1,date_str_2,date_str_3]\n",
    "pattern = re.compile(r\"\\d{1,2}[-/]\\d{1,2}[-/]\\d{4}\")\n",
    "lst_pos = [re.search(pattern,string).group(0) for string in lst_pre]\n",
    "for x,search in enumerate(lst_pos):\n",
    "    dt_obj = datetime.strptime(search, \"%m/%d/%Y\")\n",
    "    print(f\"Match {x}:\",search, f\"\\tType: {type(search)}\")\n",
    "    print(f\"DateT {x}:\",dt_obj.strftime(\"%m/%d/%Y\"), f\"\\tType: {type(dt_obj)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match 0: 12/5/2o0o \tType: <class 'str'>\n",
      "Clean 0: 12/5/2000 \tType: <class 'str'>\n",
      "\n",
      "Match 1: 6/o5/2017 \tType: <class 'str'>\n",
      "Clean 1: 6/05/2017 \tType: <class 'str'>\n",
      "\n",
      "Match 2: 01/1/20o7 \tType: <class 'str'>\n",
      "Clean 2: 01/1/2007 \tType: <class 'str'>\n",
      "\n",
      "Match 3: 1o/1/2o09 \tType: <class 'str'>\n",
      "Clean 3: 10/1/2009 \tType: <class 'str'>\n",
      "\n",
      "Match 4: o1/1o/2oo7 \tType: <class 'str'>\n",
      "Clean 4: 01/10/2007 \tType: <class 'str'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_str_1 = \"Today’s date is 12/5/2o0o\"\n",
    "date_str_2 = \"Today’s date is 6/o5/2017\"\n",
    "date_str_3 = \"Today’s date is 01/1/20o7\"\n",
    "date_str_4 = \"Today’s date is 1o/1/2o09\"\n",
    "date_str_5 = \"Today’s date is o1/1o/2oo7\"\n",
    "\n",
    "lst_pre = [date_str_1,date_str_2,date_str_3,date_str_4,date_str_5]\n",
    "pattern = re.compile(r\"o?\\d{1,2}o?[-/]o?\\d{1,2}o?[-/]\\d{1,2}(?:0o|o0|00|0|o|0o0|o0o)*\\d{0,2}\")\n",
    "lst_pos = [re.search(pattern,string).group(0) for string in lst_pre]\n",
    "for x,search in enumerate(lst_pos):\n",
    "    print(f\"Match {x}:\",search, f\"\\tType: {type(search)}\")\n",
    "    print(f\"Clean {x}:\",search.replace(\"o\",\"0\"), f\"\\tType: {type(search)}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL', 'BAC', 'GE', 'TSLA']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_sentence = \"The stocks AAPL, BAC, and GE rallied in the market last week, but FAAKE or S but TSLA\"\n",
    "pattern = re.compile(r\"\\b[A-Z]{2,4}\\b\")\n",
    "re.findall(pattern,stock_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jerome', 'Powell'), ('Mario', 'Draghi')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_wrd_seq = \"The markets listened to what Jerome Powell was going to say following the press conference with Mario Draghi, but JoHn smiTh\"\n",
    "pattern = re.compile(r\"(\\b[A-Z][a-z]+)\\s([A-Z][a-z]+)\")\n",
    "re.findall(pattern,two_wrd_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165 entries, 0 to 164\n",
      "Columns: 1664 entries, aaa to york\n",
      "dtypes: float64(1664)\n",
      "memory usage: 2.1 MB\n",
      "None \n",
      "\n",
      "\n",
      "Shape : (165, 1664) \n",
      "\n",
      "\n",
      "Size  : 274560 Elements\n",
      "165 Rows * 1664 Cols = 274560 \n",
      "\n",
      "\n",
      "Max Word: bank \tValue: 0.5398033313643824\n",
      "Min Word: aaa \tValue: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "path = \"FOMC_minutes.csv\"\n",
    "data = pd.read_csv(path)\n",
    "corp = data.statements.apply(lambda row: re.sub(\"\\d+|[^a-zA-Z0-9]\",\" \",row))\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "Y = vectorizer.fit_transform(corp)\n",
    "\n",
    "df_tfidf = pd.DataFrame(columns = vectorizer.get_feature_names(),\n",
    "                        data = Y.toarray())\n",
    "\n",
    "print(df_tfidf.info(),\"\\n\\n\")\n",
    "print(\"Shape :\",df_tfidf.shape,\"\\n\\n\")\n",
    "print(\"Size  :\",df_tfidf.size,\"Elements\")\n",
    "print(\"165 Rows * 1664 Cols =\",165*1664,\"\\n\\n\")\n",
    "x_max,y_max = df_tfidf.stack().index[np.argmax(df_tfidf.values)]\n",
    "x_min,y_min = df_tfidf.stack().index[np.argmin(df_tfidf.values)]\n",
    "print(\"Max Word:\",y_max,\"\\tValue:\",df_tfidf.loc[x_max,y_max])\n",
    "print(\"Min Word:\",y_min,\"\\tValue:\",df_tfidf.loc[x_min,y_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the Resulting Matrix:\n",
    "\n",
    "The TfidfVectorizer follows a similar methodology to the Count Vectorizer which itself creates a document term matrix. To understand this concept I will first explain it in laymans terms... a document-term matrix provides us a bag-of-words model, in which the module (scikit-learn) breaks up the corpus (consisting of individual documents, basically each row of the original dataframe) into individual words/strings/numbers usually based on a delimiter \" \". These strings are considered tokens and they make up the columns of the vectorized dataframe, in which each row represents a different document. So the document term matrix holds individual documents as rows and tokens as columns. Therefore this becomes very useful to describe the frequency of tokens over all documents. \n",
    "\n",
    "Now the Term Frequency Inverse Document Frequency Vectorizer follows a unique input methodology to the term matrix. It bases the individual values on a weighting scheme that provides a frequency to evaluate the importance of a word within a document relative to the entire corpus. So the values with higher weight represent a term that is more rare in the corpus, and vice versa. The reason Tfidf differentiates itself from a regular Count Vectorizer, is that it applies a weighting formula so that a word is given a count value relative to other words. So just because the word \"the\" appears many times times in a document doesn't make it special, rather a Tfidf Vectorizer formulizes that since the word \"the\" is seen very often across all documents, then it really doesn't have much importance, and therefore receives a lower score. So a word like \"bank\" (max value seen above) has a high score because it is more rare than other words. Meanwhile a word like \"aaa\" received the lowest score because it is probably used very often!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abate</th>\n",
       "      <th>abating</th>\n",
       "      <th>ability</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>accelerated</th>\n",
       "      <th>...</th>\n",
       "      <th>workers</th>\n",
       "      <th>working</th>\n",
       "      <th>works</th>\n",
       "      <th>would</th>\n",
       "      <th>written</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yellen</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  abate  abating  ability  about  above  abroad  absence  absent  \\\n",
       "0  0.0    0.0      0.0      0.0    0.0    0.0     0.0      0.0     0.0   \n",
       "1  0.0    0.0      0.0      0.0    0.0    0.0     0.0      0.0     0.0   \n",
       "2  0.0    0.0      0.0      0.0    0.0    0.0     0.0      0.0     0.0   \n",
       "3  0.0    0.0      0.0      0.0    0.0    0.0     0.0      0.0     0.0   \n",
       "4  0.0    0.0      0.0      0.0    0.0    0.0     0.0      0.0     0.0   \n",
       "\n",
       "   accelerated    ...     workers  working  works  would  written      year  \\\n",
       "0          0.0    ...         0.0      0.0    0.0    0.0      0.0  0.000000   \n",
       "1          0.0    ...         0.0      0.0    0.0    0.0      0.0  0.000000   \n",
       "2          0.0    ...         0.0      0.0    0.0    0.0      0.0  0.000000   \n",
       "3          0.0    ...         0.0      0.0    0.0    0.0      0.0  0.054593   \n",
       "4          0.0    ...         0.0      0.0    0.0    0.0      0.0  0.000000   \n",
       "\n",
       "   years  yellen  yet      york  \n",
       "0    0.0     0.0  0.0  0.000000  \n",
       "1    0.0     0.0  0.0  0.000000  \n",
       "2    0.0     0.0  0.0  0.000000  \n",
       "3    0.0     0.0  0.0  0.060695  \n",
       "4    0.0     0.0  0.0  0.070806  \n",
       "\n",
       "[5 rows x 1664 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
